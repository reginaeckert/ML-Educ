{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load in skills dataframe\n",
    "skill_df = pd.read_csv('skill.tsv', sep='\\t').drop('Unnamed: 0', axis=1)\n",
    "#Load in dictionary associating skill numbers with skill names\n",
    "skill_dict = {}\n",
    "with open('skill_dict.json', 'r', encoding='utf-8') as f:\n",
    "    loaded = json.load(f)\n",
    "    for v, k in loaded.items():\n",
    "        skill_dict[k] = str(v) #Use number as key, string as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Read out the \"sentences\"\n",
    "sentences=skill_df.iloc[:,1:].values.astype(str)\n",
    "sentences=sentences.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Each student is a \"sentence\", each skill is a \"word\"\n",
    "#size = dimensionality of feature vectors\n",
    "#window = max distance between current and predicted word within a sentence\n",
    "#min_count = minimum number of occurrences within dataset\n",
    "#workers = number of threads used\n",
    "#sg = 0 (CBOW, default); = 1 (skip-gram)\n",
    "model = Word2Vec(sentences, size=200, window=10, min_count=10, workers=4, sg=1, iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skill_num=model.wv.vocab; #Names of the words (numbers)\n",
    "skill_vec=model[skill_num] #Access the vectors\n",
    "\n",
    "skill_name=list()\n",
    "#Associate with readable words\n",
    "for k,v in skill_num.items(): #Iterate over the vocab from word2vec (k = key = number string)\n",
    "    skill_name.append(skill_dict.get(k)) #Get the value (tag) saved at that key in the other dict\n",
    "#print(skill_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne=TSNE(perplexity=30) #Instantiate the TSNE model (can change params here)\n",
    "skill_tsne=tsne.fit_transform(skill_vec) #Run tsne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save as a tsv file for d3-scatterplot\n",
    "# d={'x': skill_tsne[:,0],\n",
    "#   'y': skill_tsne[:,1],\n",
    "#   'skill' : skill_name}\n",
    "tsne_save=pd.DataFrame({'x': skill_tsne[:,0],\n",
    "  'y': skill_tsne[:,1],\n",
    "  'skill' : skill_name})\n",
    "tsne_save.to_csv('../d3-scatterplot/tsne_skills.tsv',sep='\\t',index=False,columns=['x','y','skill'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method to_csv in module pandas.core.frame:\n",
      "\n",
      "to_csv(path_or_buf=None, sep=',', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, mode='w', encoding=None, compression=None, quoting=None, quotechar='\"', line_terminator='\\n', chunksize=None, tupleize_cols=False, date_format=None, doublequote=True, escapechar=None, decimal='.') method of pandas.core.frame.DataFrame instance\n",
      "    Write DataFrame to a comma-separated values (csv) file\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : string or file handle, default None\n",
      "        File path or object, if None is provided the result is returned as\n",
      "        a string.\n",
      "    sep : character, default ','\n",
      "        Field delimiter for the output file.\n",
      "    na_rep : string, default ''\n",
      "        Missing data representation\n",
      "    float_format : string, default None\n",
      "        Format string for floating point numbers\n",
      "    columns : sequence, optional\n",
      "        Columns to write\n",
      "    header : boolean or list of string, default True\n",
      "        Write out column names. If a list of string is given it is assumed\n",
      "        to be aliases for the column names\n",
      "    index : boolean, default True\n",
      "        Write row names (index)\n",
      "    index_label : string or sequence, or False, default None\n",
      "        Column label for index column(s) if desired. If None is given, and\n",
      "        `header` and `index` are True, then the index names are used. A\n",
      "        sequence should be given if the DataFrame uses MultiIndex.  If\n",
      "        False do not print fields for index names. Use index_label=False\n",
      "        for easier importing in R\n",
      "    mode : str\n",
      "        Python write mode, default 'w'\n",
      "    encoding : string, optional\n",
      "        A string representing the encoding to use in the output file,\n",
      "        defaults to 'ascii' on Python 2 and 'utf-8' on Python 3.\n",
      "    compression : string, optional\n",
      "        a string representing the compression to use in the output file,\n",
      "        allowed values are 'gzip', 'bz2', 'xz',\n",
      "        only used when the first argument is a filename\n",
      "    line_terminator : string, default ``'\\n'``\n",
      "        The newline character or character sequence to use in the output\n",
      "        file\n",
      "    quoting : optional constant from csv module\n",
      "        defaults to csv.QUOTE_MINIMAL. If you have set a `float_format`\n",
      "        then floats are converted to strings and thus csv.QUOTE_NONNUMERIC\n",
      "        will treat them as non-numeric\n",
      "    quotechar : string (length 1), default '\\\"'\n",
      "        character used to quote fields\n",
      "    doublequote : boolean, default True\n",
      "        Control quoting of `quotechar` inside a field\n",
      "    escapechar : string (length 1), default None\n",
      "        character used to escape `sep` and `quotechar` when appropriate\n",
      "    chunksize : int or None\n",
      "        rows to write at a time\n",
      "    tupleize_cols : boolean, default False\n",
      "        write multi_index columns as a list of tuples (if True)\n",
      "        or new (expanded format) if False)\n",
      "    date_format : string, default None\n",
      "        Format string for datetime objects\n",
      "    decimal: string, default '.'\n",
      "        Character recognized as decimal separator. E.g. use ',' for\n",
      "        European data\n",
      "    \n",
      "        .. versionadded:: 0.16.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tsne_save.to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class TSNE in module sklearn.manifold.t_sne:\n",
      "\n",
      "class TSNE(sklearn.base.BaseEstimator)\n",
      " |  t-distributed Stochastic Neighbor Embedding.\n",
      " |  \n",
      " |  t-SNE [1] is a tool to visualize high-dimensional data. It converts\n",
      " |  similarities between data points to joint probabilities and tries\n",
      " |  to minimize the Kullback-Leibler divergence between the joint\n",
      " |  probabilities of the low-dimensional embedding and the\n",
      " |  high-dimensional data. t-SNE has a cost function that is not convex,\n",
      " |  i.e. with different initializations we can get different results.\n",
      " |  \n",
      " |  It is highly recommended to use another dimensionality reduction\n",
      " |  method (e.g. PCA for dense data or TruncatedSVD for sparse data)\n",
      " |  to reduce the number of dimensions to a reasonable amount (e.g. 50)\n",
      " |  if the number of features is very high. This will suppress some\n",
      " |  noise and speed up the computation of pairwise distances between\n",
      " |  samples. For more tips see Laurens van der Maaten's FAQ [2].\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <t_sne>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_components : int, optional (default: 2)\n",
      " |      Dimension of the embedded space.\n",
      " |  \n",
      " |  perplexity : float, optional (default: 30)\n",
      " |      The perplexity is related to the number of nearest neighbors that\n",
      " |      is used in other manifold learning algorithms. Larger datasets\n",
      " |      usually require a larger perplexity. Consider selecting a value\n",
      " |      between 5 and 50. The choice is not extremely critical since t-SNE\n",
      " |      is quite insensitive to this parameter.\n",
      " |  \n",
      " |  early_exaggeration : float, optional (default: 4.0)\n",
      " |      Controls how tight natural clusters in the original space are in\n",
      " |      the embedded space and how much space will be between them. For\n",
      " |      larger values, the space between natural clusters will be larger\n",
      " |      in the embedded space. Again, the choice of this parameter is not\n",
      " |      very critical. If the cost function increases during initial\n",
      " |      optimization, the early exaggeration factor or the learning rate\n",
      " |      might be too high.\n",
      " |  \n",
      " |  learning_rate : float, optional (default: 1000)\n",
      " |      The learning rate can be a critical parameter. It should be\n",
      " |      between 100 and 1000. If the cost function increases during initial\n",
      " |      optimization, the early exaggeration factor or the learning rate\n",
      " |      might be too high. If the cost function gets stuck in a bad local\n",
      " |      minimum increasing the learning rate helps sometimes.\n",
      " |  \n",
      " |  n_iter : int, optional (default: 1000)\n",
      " |      Maximum number of iterations for the optimization. Should be at\n",
      " |      least 200.\n",
      " |  \n",
      " |  n_iter_without_progress : int, optional (default: 30)\n",
      " |      Only used if method='exact'\n",
      " |      Maximum number of iterations without progress before we abort the\n",
      " |      optimization. If method='barnes_hut' this parameter is fixed to\n",
      " |      a value of 30 and cannot be changed.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         parameter *n_iter_without_progress* to control stopping criteria.\n",
      " |  \n",
      " |  min_grad_norm : float, optional (default: 1e-7)\n",
      " |      Only used if method='exact'\n",
      " |      If the gradient norm is below this threshold, the optimization will\n",
      " |      be aborted. If method='barnes_hut' this parameter is fixed to a value\n",
      " |      of 1e-3 and cannot be changed.\n",
      " |  \n",
      " |  metric : string or callable, optional\n",
      " |      The metric to use when calculating distance between instances in a\n",
      " |      feature array. If metric is a string, it must be one of the options\n",
      " |      allowed by scipy.spatial.distance.pdist for its metric parameter, or\n",
      " |      a metric listed in pairwise.PAIRWISE_DISTANCE_FUNCTIONS.\n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix.\n",
      " |      Alternatively, if metric is a callable function, it is called on each\n",
      " |      pair of instances (rows) and the resulting value recorded. The callable\n",
      " |      should take two arrays from X as input and return a value indicating\n",
      " |      the distance between them. The default is \"euclidean\" which is\n",
      " |      interpreted as squared euclidean distance.\n",
      " |  \n",
      " |  init : string or numpy array, optional (default: \"random\")\n",
      " |      Initialization of embedding. Possible options are 'random', 'pca',\n",
      " |      and a numpy array of shape (n_samples, n_components).\n",
      " |      PCA initialization cannot be used with precomputed distances and is\n",
      " |      usually more globally stable than random initialization.\n",
      " |  \n",
      " |  verbose : int, optional (default: 0)\n",
      " |      Verbosity level.\n",
      " |  \n",
      " |  random_state : int or RandomState instance or None (default)\n",
      " |      Pseudo Random Number generator seed control. If None, use the\n",
      " |      numpy.random singleton. Note that different initializations\n",
      " |      might result in different local minima of the cost function.\n",
      " |  \n",
      " |  method : string (default: 'barnes_hut')\n",
      " |      By default the gradient calculation algorithm uses Barnes-Hut\n",
      " |      approximation running in O(NlogN) time. method='exact'\n",
      " |      will run on the slower, but exact, algorithm in O(N^2) time. The\n",
      " |      exact algorithm should be used when nearest-neighbor errors need\n",
      " |      to be better than 3%. However, the exact method cannot scale to\n",
      " |      millions of examples.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Approximate optimization *method* via the Barnes-Hut.\n",
      " |  \n",
      " |  angle : float (default: 0.5)\n",
      " |      Only used if method='barnes_hut'\n",
      " |      This is the trade-off between speed and accuracy for Barnes-Hut T-SNE.\n",
      " |      'angle' is the angular size (referred to as theta in [3]) of a distant\n",
      " |      node as measured from a point. If this size is below 'angle' then it is\n",
      " |      used as a summary node of all points contained within it.\n",
      " |      This method is not very sensitive to changes in this parameter\n",
      " |      in the range of 0.2 - 0.8. Angle less than 0.2 has quickly increasing\n",
      " |      computation time and angle greater 0.8 has quickly increasing error.\n",
      " |  \n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  embedding_ : array-like, shape (n_samples, n_components)\n",
      " |      Stores the embedding vectors.\n",
      " |  \n",
      " |  kl_divergence_ : float\n",
      " |      Kullback-Leibler divergence after optimization.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  \n",
      " |  >>> import numpy as np\n",
      " |  >>> from sklearn.manifold import TSNE\n",
      " |  >>> X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
      " |  >>> model = TSNE(n_components=2, random_state=0)\n",
      " |  >>> np.set_printoptions(suppress=True)\n",
      " |  >>> model.fit_transform(X) # doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE\n",
      " |  array([[ 0.00017599,  0.00003993],\n",
      " |         [ 0.00009891,  0.00021913],\n",
      " |         [ 0.00018554, -0.00009357],\n",
      " |         [ 0.00009528, -0.00001407]])\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  [1] van der Maaten, L.J.P.; Hinton, G.E. Visualizing High-Dimensional Data\n",
      " |      Using t-SNE. Journal of Machine Learning Research 9:2579-2605, 2008.\n",
      " |  \n",
      " |  [2] van der Maaten, L.J.P. t-Distributed Stochastic Neighbor Embedding\n",
      " |      http://homepage.tudelft.nl/19j49/t-SNE.html\n",
      " |  \n",
      " |  [3] L.J.P. van der Maaten. Accelerating t-SNE using Tree-Based Algorithms.\n",
      " |      Journal of Machine Learning Research 15(Oct):3221-3245, 2014.\n",
      " |      http://lvdmaaten.github.io/publications/papers/JMLR_2014.pdf\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      TSNE\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_components=2, perplexity=30.0, early_exaggeration=4.0, learning_rate=1000.0, n_iter=1000, n_iter_without_progress=30, min_grad_norm=1e-07, metric='euclidean', init='random', verbose=0, random_state=None, method='barnes_hut', angle=0.5)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Fit X into an embedded space.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array, shape (n_samples, n_features) or (n_samples, n_samples)\n",
      " |          If the metric is 'precomputed' X must be a square distance\n",
      " |          matrix. Otherwise it contains a sample per row. If the method\n",
      " |          is 'exact', X may be a sparse matrix of type 'csr', 'csc'\n",
      " |          or 'coo'.\n",
      " |  \n",
      " |  fit_transform(self, X, y=None)\n",
      " |      Fit X into an embedded space and return that transformed\n",
      " |      output.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array, shape (n_samples, n_features) or (n_samples, n_samples)\n",
      " |          If the metric is 'precomputed' X must be a square distance\n",
      " |          matrix. Otherwise it contains a sample per row.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : array, shape (n_samples, n_components)\n",
      " |          Embedding of the training data in low-dimensional space.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(TSNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [pythonEnv]",
   "language": "python",
   "name": "Python [pythonEnv]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
